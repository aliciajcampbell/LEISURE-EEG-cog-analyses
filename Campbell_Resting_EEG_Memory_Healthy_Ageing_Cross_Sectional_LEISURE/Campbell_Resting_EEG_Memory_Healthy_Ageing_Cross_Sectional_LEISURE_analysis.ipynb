{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *[Working Title]* Resting-State EEG Aperiodic Exponent Moderates the Association Between Age and Memory Performance in Older Adults\n",
    "\n",
    "Alicia J. Campbell, Toomas Erik Anijärv, Mikael Johansson, Jim Lagopoulos, Daniel F. Hermens, Jacob M. Levenstein, & Sophie C. Andrews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "import warnings\n",
    "import statsmodels.stats.multitest as smm\n",
    "from HLR import HierarchicalLinearRegression\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsample_df = pd.read_csv('data/leisure_t1_demo_cantab_resting_eeg_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exclusions\n",
    "\n",
    "# Less than 50% epochs remaining after artifact rejection \n",
    "# (do not use for alpha or aperiodic analysis)\n",
    "       \n",
    "    # ID: [36] n=1\n",
    "\n",
    "# The fit of the parameterized power spectrum to the original PSD was below a cut-off of explained variance (R2) < .9 \n",
    "# (do not use for alpha or aperiodic analysis)\n",
    "\n",
    "    # Fronto-central: [ID : 9, 93, 119] n=3\n",
    "\n",
    "# Bad aperiodic fit as per visual inspection (i.e., fit includes significant omissions of signal) (do not use for alpha or aperiodic analysis)\n",
    "\n",
    "    # Parieto-occipital: [ID : 14, 118, 119] n=3\n",
    "    # Fronto-central: [ID : 16, 38, 61, 118] n=4\n",
    "\n",
    "# No individual alpha peak could be detected. \n",
    "# (still use for aperiodic analyses)\n",
    "\n",
    "    # Parieto-occipital: [ID : 61, 75, 93] n=3\n",
    "    # Fronto-central [ID : 14, 80, 130] n=3\n",
    "\n",
    "#### Exclusions together per measure:\n",
    "\n",
    "    # IAF_po [ID :  14, 16, 36, 113, 118, 120] n=6\n",
    "    # Exponent_po [ID :  14, 36, 113, 118, 119] n=6\n",
    "    # IAF_fc [ID : 9, 14, 16, 36, 38, 61, 80, 93, 109, 119, 118, 130] n=11\n",
    "    # Exponent_fc [ID : 9, 16, 36, 38, 61, 93, 118, 119] n=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to process\n",
    "variables = ['Exponent_po', 'Exponent_fc', 'IAF_po', 'IAF_fc']\n",
    "\n",
    "# Dictionary of subjects to exclude for each variable\n",
    "exclude_subjects = {\n",
    "    'Exponent_po': [14, 36, 118, 119],\n",
    "    'Exponent_fc': [9, 16, 36, 38, 61, 93, 118, 119],\n",
    "    'IAF_po': [14, 36, 61, 75, 93, 118, 119 ],\n",
    "    'IAF_fc': [9, 14, 16, 36, 38, 61, 80, 93, 118, 119, 130]\n",
    "}\n",
    "\n",
    "# Exclude specified subjects and create new columns with the suffix '_EX'\n",
    "for var in variables:\n",
    "    subjects_to_exclude = exclude_subjects.get(var, [])\n",
    "    mask = fullsample_df['Subject'].isin(subjects_to_exclude)\n",
    "    fullsample_df[var + '_EX'] = fullsample_df.loc[~mask, var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IDENTIFY OUTLIERS\n",
    "\n",
    "columns_to_check = ['Education', 'Exponent_po_EX', 'Exponent_fc_EX', 'IAF_po_EX', 'IAF_fc_EX', 'DMSPCAD', 'PALTEA', 'SWMBE'] \n",
    "\n",
    "df_vis = fullsample_df.dropna(subset=columns_to_check)\n",
    "\n",
    "# Plotting z-scores for visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "for col in columns_to_check:\n",
    "    # Calculate z-scores on the fly\n",
    "    zs = stats.zscore(df_vis[col])\n",
    "    plt.plot(df_vis['Subject'], zs, marker='o', linestyle='none', label=f'{col} z-score')\n",
    "plt.axhline(3, color='red', linestyle='--', label='Outlier threshold (+3)')\n",
    "plt.axhline(-3, color='green', linestyle='--', label='Outlier threshold (-3)')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Z-Score')\n",
    "plt.title('Z-Scores of Columns')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Identify outliers and the associated subject and column\n",
    "outliers = []\n",
    "for col in columns_to_check:\n",
    "    zs = stats.zscore(df_vis[col])\n",
    "    for idx, z in enumerate(zs):\n",
    "        if z > 3 or z < -3:\n",
    "            # Use .iloc to ensure correct positional indexing\n",
    "            outliers.append((df_vis.iloc[idx]['Subject'], col, df_vis.iloc[idx][col], z))\n",
    "\n",
    "# Print outlier information\n",
    "print(\"Outliers found:\")\n",
    "for outlier in outliers:\n",
    "    print(f\"Subject: {outlier[0]}, Column: {outlier[1]}, Value: {outlier[2]}, Z-Score: {outlier[3]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Age', 'Gender_F', 'Education', 'Handedness_right', \n",
    "                    'DMSPCAD', 'PALTEA', 'SWMBE', \n",
    "                    'IAF_fc_EX', 'Exponent_fc_EX', 'IAF_po_EX', 'Exponent_po_EX']\n",
    "\n",
    "# Clean the data by removing rows with missing values\n",
    "df_skew = fullsample_df.dropna(subset=columns_to_check)\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "skewness = df_skew[columns_to_check].skew()\n",
    "kurtosis = df_skew[columns_to_check].kurtosis()\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "skewness_kurtosis_df = pd.DataFrame({\n",
    "    'Skewness': skewness,\n",
    "    'Kurtosis': kurtosis\n",
    "}).round(3)\n",
    "\n",
    "print(skewness_kurtosis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsample_df_outliers_clean = fullsample_df.copy()\n",
    "\n",
    "### Winsorize outliers (Z-score: >3)\n",
    "\n",
    "column_to_adjust = ['Education', 'SWMBE', 'IAF_fc_EX'] \n",
    "\n",
    "def safe_winsorize(series, z_threshold=3):\n",
    "    \"\"\"Winsorize based on dynamic z-score thresholds\"\"\"\n",
    "    zs = stats.zscore(series, nan_policy='omit')\n",
    "    upper_bound = series[zs <= z_threshold].max()\n",
    "    lower_bound = series[zs >= -z_threshold].min()\n",
    "    # return lower_bound, upper_bound\n",
    "    return series.clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Apply to create _OA columns\n",
    "for col in column_to_adjust:\n",
    "    fullsample_df_outliers_clean.loc[:, f'{col}_OA'] = safe_winsorize(fullsample_df_outliers_clean[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Education_OA', 'Exponent_po_EX', 'Exponent_fc_EX', 'IAF_po_EX', 'IAF_fc_EX_OA', 'DMSPCAD', 'PALTEA', 'SWMBE_OA'] \n",
    "\n",
    "df_vis = fullsample_df_outliers_clean.dropna(subset=columns_to_check)\n",
    "\n",
    "# Plotting z-scores for visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "for col in columns_to_check:\n",
    "    # Calculate z-scores on the fly\n",
    "    zs = stats.zscore(df_vis[col])\n",
    "    plt.plot(df_vis['Subject'], zs, marker='o', linestyle='none', label=f'{col} z-score')\n",
    "plt.axhline(3, color='red', linestyle='--', label='Outlier threshold (+3)')\n",
    "plt.axhline(-3, color='green', linestyle='--', label='Outlier threshold (-3)')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Z-Score')\n",
    "plt.title('Z-Scores of Columns')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Identify outliers and the associated subject and column\n",
    "outliers = []\n",
    "for col in columns_to_check:\n",
    "    zs = stats.zscore(df_vis[col])\n",
    "    for idx, z in enumerate(zs):\n",
    "        if z > 3 or z < -3:\n",
    "            # Use .iloc to ensure correct positional indexing\n",
    "            outliers.append((df_vis.iloc[idx]['Subject'], col, df_vis.iloc[idx][col], z))\n",
    "\n",
    "# Print outlier information\n",
    "print(\"Outliers found:\")\n",
    "for outlier in outliers:\n",
    "    print(f\"Subject: {outlier[0]}, Column: {outlier[1]}, Value: {outlier[2]}, Z-Score: {outlier[3]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Education_OA', 'IAF_fc_EX_OA', 'SWMBE_OA']\n",
    "\n",
    "# Clean the data by removing rows with missing values\n",
    "df_skew_corrected = fullsample_df_outliers_clean.dropna(subset=columns_to_check)\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "skewness = df_skew_corrected[columns_to_check].skew()\n",
    "kurtosis = df_skew_corrected[columns_to_check].kurtosis()\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "skewness_kurtosis_corrected_df = pd.DataFrame({\n",
    "    'Skewness': skewness,\n",
    "    'Kurtosis': kurtosis\n",
    "}).round(3)\n",
    "\n",
    "print(skewness_kurtosis_corrected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score continuous variables\n",
    "columns_to_zscore = ['Age', 'Education_OA', 'DMSPCAD', 'PALTEA', 'SWMBE_OA', 'Exponent_po_EX', 'Exponent_fc_EX', 'IAF_po_EX', 'IAF_fc_EX_OA']\n",
    "\n",
    "fullsample_df_outliers_clean_z = fullsample_df_outliers_clean.copy()\n",
    "\n",
    "for column in columns_to_zscore:\n",
    "    mean_val = fullsample_df_outliers_clean_z[column].mean()\n",
    "    std_val = fullsample_df_outliers_clean_z[column].std()\n",
    "    fullsample_df_outliers_clean_z.loc[:, column + '_z'] = (fullsample_df_outliers_clean_z[column] - mean_val) / std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to include in the new DataFrame\n",
    "columns_to_include = ['Subject', \n",
    "                      'Age', 'Age_z',\n",
    "                      'Gender_F', \n",
    "                      'Education_OA', 'Education_OA_z',\n",
    "                      'Handedness_right', \n",
    "                      'IAF_po_EX', 'IAF_po_EX_z',\n",
    "                      'IAF_fc_EX_OA', 'IAF_fc_EX_OA_z',\n",
    "                      'Exponent_po_EX', 'Exponent_po_EX_z',\n",
    "                      'Exponent_fc_EX','Exponent_fc_EX_z',\n",
    "                      'DMSPCAD', 'DMSPCAD_z',\n",
    "                      'PALTEA', 'PALTEA_z',\n",
    "                      'SWMBE_OA', 'SWMBE_OA_z']\n",
    "\n",
    "# Create a new DataFrame with only the selected columns and make a copy\n",
    "fullsample_df_CLEAN = fullsample_df_outliers_clean_z[columns_to_include].copy()\n",
    "\n",
    "# Dictionary of old column names and new column names\n",
    "new_column_names = {\n",
    "    'Education_OA': 'Education',\n",
    "    'Education_OA_z': 'Education_z',\n",
    "    'IAF_po_EX': 'IAF_po',\n",
    "    'IAF_po_EX_z': 'IAF_po_z',\n",
    "    'IAF_fc_EX_OA': 'IAF_fc',\n",
    "    'IAF_fc_EX_OA_z':'IAF_fc_z',\n",
    "    'Exponent_po_EX': 'Exponent_po',\n",
    "    'Exponent_po_EX_z': 'Exponent_po_z',\n",
    "    'Exponent_fc_EX': 'Exponent_fc',\n",
    "    'Exponent_fc_EX_z': 'Exponent_fc_z',\n",
    "    'SWMBE_OA': 'SWMBE',\n",
    "    'SWMBE_OA_z': 'SWMBE_z'}\n",
    "\n",
    "# Rename the columns in the new DataFrame\n",
    "fullsample_df_CLEAN.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction terms dictionary\n",
    "interaction_terms = {\n",
    "    'Age_Exponent_po': ['Age_z', 'Exponent_po_z'],\n",
    "    'Age_IAF_po': ['Age_z', 'IAF_po_z'],\n",
    "    'Age_Exponent_fc': ['Age_z', 'Exponent_fc_z'],\n",
    "    'Age_IAF_fc': ['Age_z', 'IAF_fc_z']\n",
    "}\n",
    "\n",
    "# Compute interaction terms\n",
    "for interaction_name, columns in interaction_terms.items():\n",
    "    col1, col2 = columns\n",
    "    mask = fullsample_df_CLEAN[[col1, col2]].notna().all(axis=1)\n",
    "    fullsample_df_CLEAN.loc[mask, interaction_name] = fullsample_df_CLEAN.loc[mask, col1] * fullsample_df_CLEAN.loc[mask, col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullsample_df_CLEAN.to_csv('data/leisure_t1_demo_cantab_resting_eeg_clean_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsample_df_CLEAN = pd.read_csv('data/leisure_t1_demo_cantab_resting_eeg_clean_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_females = fullsample_df_CLEAN['Gender_F'].sum()\n",
    "print(f\"Number of females: {num_females}\")\n",
    "\n",
    "num_righthanded = fullsample_df_CLEAN['Handedness_right'].sum()\n",
    "print(f\"Number of right handed: {num_righthanded}\")\n",
    "\n",
    "\n",
    "\n",
    "descriptives_df = fullsample_df_CLEAN[['Age', 'Education', 'DMSPCAD', 'PALTEA', 'SWMBE', 'IAF_fc', 'Exponent_fc', 'IAF_po', 'Exponent_po']].describe().round(2)\n",
    "filtered_stats = descriptives_df.loc[['count', 'mean', 'std', 'min', 'max']]\n",
    "\n",
    "# filtered_stats.to_csv('results/sampledescriptives.csv')\n",
    "\n",
    "display(filtered_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Spearman correlations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "correlation_list = ['Age', 'DMSPCAD', 'PALTEA', 'SWMBE', 'IAF_fc', 'Exponent_fc', 'IAF_po', 'Exponent_po']\n",
    "\n",
    "correlation_matrix = pd.DataFrame(index=correlation_list, columns=correlation_list)\n",
    "p_value_matrix = pd.DataFrame(index=correlation_list, columns=correlation_list)\n",
    "\n",
    "all_p_values = []\n",
    "p_value_locs = []\n",
    "\n",
    "# Compute pairwise Spearman correlation and p-values\n",
    "for col1 in correlation_list:\n",
    "    for col2 in correlation_list:\n",
    "        if col1 == col2:\n",
    "            correlation_matrix.loc[col1, col2] = 1.000  \n",
    "            p_value_matrix.loc[col1, col2] = np.nan  \n",
    "        else:\n",
    "            valid_data = fullsample_df_CLEAN[[col1, col2]].dropna()\n",
    "            \n",
    "            if not valid_data.empty:\n",
    "                corr, p_value = spearmanr(valid_data[col1], valid_data[col2])\n",
    "                \n",
    "                correlation_matrix.loc[col1, col2] = f\"{corr:.3f}\"\n",
    "                p_value_matrix.loc[col1, col2] = p_value\n",
    "                \n",
    "                all_p_values.append(p_value)\n",
    "                p_value_locs.append((col1, col2))\n",
    "            else:\n",
    "                correlation_matrix.loc[col1, col2] = np.nan\n",
    "                p_value_matrix.loc[col1, col2] = np.nan\n",
    "\n",
    "## Untoggle for raw p values\n",
    "# Apply FDR correction to the list of p-values\n",
    "rejected, pvals_corrected, _, _ = multipletests(all_p_values, alpha=0.05, method='fdr_bh')\n",
    "# Replace the original p-values in the matrix with the FDR-corrected p-values\n",
    "for idx, (col1, col2) in enumerate(p_value_locs):\n",
    "    p_value_matrix.loc[col1, col2] = pvals_corrected[idx]\n",
    "\n",
    "annot_matrix = correlation_matrix.copy()\n",
    "\n",
    "# Iterate through the p_value_matrix and format the annotations\n",
    "for col1 in correlation_list:\n",
    "    for col2 in correlation_list:\n",
    "        if pd.notna(p_value_matrix.loc[col1, col2]):\n",
    "            if p_value_matrix.loc[col1, col2] < 0.001:\n",
    "                annot_matrix.loc[col1, col2] = f\"{correlation_matrix.loc[col1, col2]}\\n(<0.001)\"\n",
    "            else:\n",
    "                annot_matrix.loc[col1, col2] = f\"{correlation_matrix.loc[col1, col2]}\\n({p_value_matrix.loc[col1, col2]:.3f})\"\n",
    "\n",
    "renaming_dict = {\n",
    "    'DMSPCAD': \"DMS PCAD\", \n",
    "    'PALTEA': \"PAL TEA\",\n",
    "    'SWMBE': \"SWM BE\",\n",
    "    'Exponent_po': \"PO exponent\", \n",
    "    'Exponent_fc': \"FC exponent\", \n",
    "    'IAF_po': \"PO IAF\", \n",
    "    'IAF_fc': \"FC IAF\",\n",
    "}\n",
    "\n",
    "correlation_matrix.rename(columns=renaming_dict, index=renaming_dict, inplace=True)\n",
    "annot_matrix.rename(columns=renaming_dict, index=renaming_dict, inplace=True)\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "cmap = plt.get_cmap(\"RdBu_r\")\n",
    "\n",
    "plt.figure(figsize=(7.5, 6), dpi=150)\n",
    "ax = sns.heatmap(\n",
    "    correlation_matrix.astype(float), \n",
    "    cmap=cmap, # coolwarm\n",
    "    fmt=\"\", \n",
    "    cbar=True, \n",
    "    mask=np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1),\n",
    "    annot=annot_matrix,\n",
    "    annot_kws={\"size\": 9},\n",
    "    linewidths=.5,\n",
    "    vmin=-1.0, \n",
    "    vmax=1.0 ,  \n",
    "    center=0.0 \n",
    ")\n",
    "\n",
    "xticklabels = ax.get_xticklabels()\n",
    "yticklabels = ax.get_yticklabels()\n",
    "\n",
    "# xticklabels[-1] = ''\n",
    "# yticklabels[0] = ''\n",
    "\n",
    "ax.set_xticklabels(xticklabels, rotation=30, ha='right', fontsize=9)\n",
    "ax.set_yticklabels(yticklabels, rotation=0, fontsize=9)\n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to file\n",
    "plt.savefig('results/plots/corrmatrix.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Heirachical linear regressions / Simple slopes analysis and plots*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_slope_analysis(model, level, var='Age_z', interaction='Age_Exponent_po'):\n",
    "    \n",
    "    # step3 model covariance matrix, coefficients, and DoF\n",
    "    b_var, b_int = model.params[var], model.params[interaction]\n",
    "    cov_matrix = model.cov_params()\n",
    "    df = model.df_resid\n",
    "\n",
    "    # calculate slope at the specified level of iv\n",
    "    slope = b_var + b_int * level\n",
    "\n",
    "    # variances and covariance from the covariance matrix\n",
    "    var_var = cov_matrix.loc[var, var]\n",
    "    var_int = cov_matrix.loc[interaction, interaction]\n",
    "    cov_age_int = cov_matrix.loc[var, interaction]\n",
    "\n",
    "    # slope SE, tval, pval, and CIs\n",
    "    se = np.sqrt(var_var + level**2 * var_int + 2 * level * cov_age_int)\n",
    "    tval = slope / se\n",
    "    pval = 2 * (1 - stats.t.cdf(np.abs(tval), df))\n",
    "    ci = [slope-stats.t.ppf(0.975, df)*se, slope+stats.t.ppf(0.975, df)*se]\n",
    "    return slope, se, tval, pval, ci\n",
    "\n",
    "dict_hlr = {}\n",
    "df_ = fullsample_df_CLEAN.copy()\n",
    "\n",
    "sns.set_theme(style='whitegrid', font='Helvetica', context='paper') \n",
    "plt.rc('grid', linestyle='-', alpha=0.3)\n",
    "plt.rcParams.update({\n",
    "    'font.size':9,\n",
    "    'axes.labelsize':9,\n",
    "    'axes.titlesize':9,\n",
    "    'xtick.labelsize':9,\n",
    "    'ytick.labelsize':9,\n",
    "    'legend.fontsize':9,\n",
    "    'legend.title_fontsize':9\n",
    "})\n",
    "(fig, axs), i = plt.subplots(1, 2, figsize=(180/25.4, 90/25.4), dpi=300), 0\n",
    "\n",
    "dict_labels = {\n",
    "    'Exponent_fc': 'Fronto-central exponent', 'Exponent_po': 'Parieto-occipital exponent',\n",
    "    'DMSPCAD_z_pred': 'DMS PCAD (z-scored)', 'PALTEA_z_pred': 'PAL TEA (z-scored)', \n",
    "}\n",
    "# colors = ['#2E627AFF', '#AEB2B7FF', '#B53737FF']\n",
    "cmap = plt.get_cmap(\"RdBu_r\")\n",
    "colors = [cmap(0.1), '#AEB2B7FF', cmap(0.825)]\n",
    "grp_conditions = {'Low (≤-1SD)':-1, 'Mean': 0, 'High (≥1SD)': 1}\n",
    "\n",
    "import os\n",
    "HLR_output_dir = 'results/hlr_summaries'\n",
    "os.makedirs(HLR_output_dir, exist_ok=True)\n",
    "\n",
    "covars = ['Age_z', 'Gender_F', 'Education_z', 'Handedness_right']\n",
    "for iv in ['Exponent_fc', 'Exponent_po', 'IAF_fc', 'IAF_po']:\n",
    "    for dv in ['DMSPCAD_z' , 'PALTEA_z', 'SWMBE_z']:\n",
    "        X = {\n",
    "            1: covars,\n",
    "            2: covars + [f'{iv}_z'],\n",
    "            3: covars + [f'Age_{iv}'] + [f'{iv}_z']\n",
    "        }\n",
    "\n",
    "        df_t = df_[['Subject', 'Age']+X[3]+[dv]].dropna()\n",
    "\n",
    "        hlr_model = HierarchicalLinearRegression(df_t, X, dv)\n",
    "        hlr_summary = hlr_model.summary()\n",
    "\n",
    "        hlr_summary_csv_path = os.path.join(HLR_output_dir, f'hlr_summary_{iv}_{dv}.csv')\n",
    "        # hlr_summary.to_csv(hlr_summary_csv_path, index=False)\n",
    "\n",
    "        # predict dv values based on final model\n",
    "        s3_model = hlr_model.fit_models()[3]\n",
    "        df_t[f'{dv}_pred'] = s3_model.predict(sm.add_constant(df_t[X[3]]))\n",
    "\n",
    "        # add HLR model and step3 LM results to dict\n",
    "        dict_hlr[(iv, dv)] = {'hlr_model': hlr_model, 'hlr_summary': hlr_summary,\n",
    "                              's3_model': s3_model, 's3_df': df_t}\n",
    "        \n",
    "        # check final model significance\n",
    "        s3_pval = hlr_summary.iloc[2]['P-value (F-value change)']\n",
    "        \n",
    "        # Within the significant model block:\n",
    "        if s3_pval < 0.05:\n",
    "            print(f'\\n---\\niv={iv}, dv={dv}, step 3 model p-val = {s3_pval:.3f}')\n",
    "\n",
    "            # 1. IV-BASED GROUPS (for Age slope analysis)\n",
    "            df_t.loc[:, 'iv_group'] = np.where(df_t[f'{iv}_z'] >= 1, 'High (≥1SD)',\n",
    "                                            np.where(df_t[f'{iv}_z'] <= -1, 'Low (≤-1SD)', 'Mean'))\n",
    "\n",
    "            desired_order = ['Low (≤-1SD)', 'Mean', 'High (≥1SD)']\n",
    "            ax = axs[i]\n",
    "            sns.scatterplot(ax=ax,x='Age_z', y=f'{dv}_pred', data=df_t, hue='iv_group', hue_order=desired_order, \n",
    "                            palette=colors, edgecolor='#494949', lw=0.8, s=20, alpha=0.7)\n",
    "            for c, g_lab in enumerate(grp_conditions.keys()):\n",
    "                sns.regplot(ax=ax, x='Age_z', y=f'{dv}_pred', data=df_t[df_t['iv_group']==g_lab], color=colors[c], scatter=False)\n",
    "            ax.legend(title=dict_labels[iv], ncols=3, loc='upper center', frameon=False, bbox_to_anchor=(0.5, 1.2), \n",
    "                      handletextpad=0.1, columnspacing=2)\n",
    "            ax.set_ylabel(dict_labels[f'{dv}_pred'])\n",
    "            ax.set_xlabel(\"Age (z-scored)\")  \n",
    "            ax.set_ylim([-1.65, 1.65])\n",
    "\n",
    "            # Slope Analysis\n",
    "            # 1. Age Slopes in IV Groups\n",
    "            print(\"\\n=== Age Effects Across IV Groups ===\")\n",
    "            for iv_group, iv_level in grp_conditions.items():\n",
    "                group_size = df_t['iv_group'].value_counts()[iv_group]\n",
    "                slope, se, tval, pval, ci = simple_slope_analysis(\n",
    "                    model=s3_model,\n",
    "                    level=iv_level,\n",
    "                    var='Age_z',\n",
    "                    interaction=f'Age_{iv}'\n",
    "                )\n",
    "                print(f\"\\n{iv_group} IV Group (n={group_size}):\")\n",
    "                print(f\"Age Slope: {slope:.3f}, SE: {se:.3f}, [95% CI: {ci[0]:.3f}, {ci[1]:.3f}], t = {tval:.3f}, p = {pval:.3f}\")\n",
    "            i += 1\n",
    "\n",
    "plt.tight_layout(pad=-0.3)\n",
    "plt.savefig('results/plots/simpleslopesplot.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_summary_df(summary_df):\n",
    "    \"\"\"Helper function to round numeric values in HLR summary DataFrame\"\"\"\n",
    "    # 1. Round top-level numeric columns\n",
    "    numeric_cols = [\n",
    "        'R-squared', 'F-value', 'P-value (F)', 'SSR', 'SSTO',\n",
    "        'MSE (model)', 'MSE (residuals)', 'MSE (total)',\n",
    "        'R-squared change', 'F-value change', 'P-value (F-value change)'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in summary_df.columns:\n",
    "            summary_df[col] = summary_df[col].round(3)\n",
    "    \n",
    "    # 2. Process dictionary columns with numeric values\n",
    "    dict_cols = [\n",
    "        'Beta coefs', 'P-values (beta coefs)', 'T-values (beta coefs)',\n",
    "        'Standard errors', 'Std Beta coefs', 'Partial correlations',\n",
    "        'Semi-partial correlations', 'Unique variance %'\n",
    "    ]\n",
    "    \n",
    "    def round_dict(d):\n",
    "        return {k: round(v, 3) if isinstance(v, (int, float)) else v \n",
    "                for k, v in d.items()} if isinstance(d, dict) else d\n",
    "    \n",
    "    for col in dict_cols:\n",
    "        if col in summary_df.columns:\n",
    "            summary_df[col] = summary_df[col].apply(round_dict)\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def simple_slope_analysis(model, level, var='Age_z', interaction='Age_Exponent_po'):\n",
    "    \n",
    "    # step3 model covariance matrix, coefficients, and DoF\n",
    "    b_var, b_int = model.params[var], model.params[interaction]\n",
    "    cov_matrix = model.cov_params()\n",
    "    df = model.df_resid\n",
    "\n",
    "    # calculate slope at the specified level of iv\n",
    "    slope = b_var + b_int * level\n",
    "\n",
    "    # variances and covariance from the covariance matrix\n",
    "    var_var = cov_matrix.loc[var, var]\n",
    "    var_int = cov_matrix.loc[interaction, interaction]\n",
    "    cov_age_int = cov_matrix.loc[var, interaction]\n",
    "\n",
    "    # slope SE, tval, pval, and CIs\n",
    "    se = np.sqrt(var_var + level**2 * var_int + 2 * level * cov_age_int)\n",
    "    tval = slope / se\n",
    "    pval = 2 * (1 - stats.t.cdf(np.abs(tval), df))\n",
    "    ci = [slope-stats.t.ppf(0.975, df)*se, slope+stats.t.ppf(0.975, df)*se]\n",
    "    return slope, se, tval, pval, ci\n",
    "\n",
    "dict_hlr = {}\n",
    "df_ = fullsample_df_CLEAN.copy()\n",
    "\n",
    "sns.set_theme(style='whitegrid', font='Helvetica', context='paper') \n",
    "plt.rc('grid', linestyle='-', alpha=0.3)\n",
    "plt.rcParams.update({\n",
    "    'font.size':9,\n",
    "    'axes.labelsize':9,\n",
    "    'axes.titlesize':9,\n",
    "    'xtick.labelsize':9,\n",
    "    'ytick.labelsize':9,\n",
    "    'legend.fontsize':9,\n",
    "    'legend.title_fontsize':9\n",
    "})\n",
    "(fig, axs), i = plt.subplots(1, 2, figsize=(180/25.4, 90/25.4), dpi=300), 0\n",
    "\n",
    "dict_labels = {\n",
    "    'Exponent_fc': 'Fronto-central exponent', 'Exponent_po': 'Parieto-occipital exponent',\n",
    "    'DMSPCAD_z_pred': 'DMS PCAD (z-scored)', 'PALTEA_z_pred': 'PAL TEA (z-scored)', \n",
    "}\n",
    "# colors = ['#2E627AFF', '#AEB2B7FF', '#B53737FF']\n",
    "cmap = plt.get_cmap(\"RdBu_r\")\n",
    "colors = [cmap(0.1), '#AEB2B7FF', cmap(0.825)]\n",
    "grp_conditions = {'Low (≤-1SD)':-1, 'Mean': 0, 'High (≥1SD)': 1}\n",
    "\n",
    "import os\n",
    "HLR_output_dir = 'results/hlr_summaries'\n",
    "os.makedirs(HLR_output_dir, exist_ok=True)\n",
    "\n",
    "# slope_output_dir = 'results/simple_slope_analyses'\n",
    "# os.makedirs(slope_output_dir, exist_ok=True)\n",
    "\n",
    "covars = ['Age_z', 'Gender_F', 'Education_z', 'Handedness_right']\n",
    "for iv in ['Exponent_fc', 'Exponent_po', 'IAF_fc', 'IAF_po']:\n",
    "    for dv in ['DMSPCAD_z' , 'PALTEA_z', 'SWMBE_z']:\n",
    "        X = {\n",
    "            1: covars,\n",
    "            2: covars + [f'{iv}_z'],\n",
    "            3: covars + [f'Age_{iv}'] + [f'{iv}_z']\n",
    "        }\n",
    "\n",
    "        df_t = df_[['Subject', 'Age']+X[3]+[dv]].dropna()\n",
    "\n",
    "        hlr_model = HierarchicalLinearRegression(df_t, X, dv)\n",
    "        hlr_summary = hlr_model.summary()\n",
    "\n",
    "        hlr_summary_rounded = round_summary_df(hlr_summary)\n",
    "\n",
    "        hlr_summary_csv_path = os.path.join(HLR_output_dir, f'hlr_summary_rounded_{iv}_{dv}.csv')\n",
    "        hlr_summary_rounded.to_csv(hlr_summary_csv_path, index=False)\n",
    "\n",
    "        # predict dv values based on final model\n",
    "        s3_model = hlr_model.fit_models()[3]\n",
    "        df_t[f'{dv}_pred'] = s3_model.predict(sm.add_constant(df_t[X[3]]))\n",
    "\n",
    "        # add HLR model and step3 LM results to dict\n",
    "        dict_hlr[(iv, dv)] = {'hlr_model': hlr_model, 'hlr_summary': hlr_summary,\n",
    "                              's3_model': s3_model, 's3_df': df_t}\n",
    "        \n",
    "        # check final model significance\n",
    "        s3_pval = hlr_summary.iloc[2]['P-value (F-value change)']\n",
    "        \n",
    "        # Within the significant model block:\n",
    "        if s3_pval < 0.05:\n",
    "            print(f'\\n---\\niv={iv}, dv={dv}, step 3 model p-val = {s3_pval:.3f}')\n",
    "\n",
    "            # 1. IV-BASED GROUPS (for Age slope analysis)\n",
    "            df_t.loc[:, 'iv_group'] = np.where(df_t[f'{iv}_z'] >= 1, 'High (≥1SD)',\n",
    "                                            np.where(df_t[f'{iv}_z'] <= -1, 'Low (≤-1SD)', 'Mean'))\n",
    "            \n",
    "            # # 2. AGE-BASED GROUPS (for IV slope analysis)\n",
    "            # age_z = (df_t['Age'] - df_t['Age'].mean())/df_t['Age'].std()\n",
    "            # df_t.loc[:, 'age_group'] = np.where(age_z >= 1, 'Old (≥1SD)',\n",
    "            #                                 np.where(age_z <= -1, 'Young (≤-1SD)', 'Middle Aged'))\n",
    "\n",
    "            desired_order = ['Low (≤-1SD)', 'Mean', 'High (≥1SD)']\n",
    "            ax = axs[i]\n",
    "            sns.scatterplot(ax=ax,x='Age_z', y=f'{dv}_pred', data=df_t, hue='iv_group', hue_order=desired_order, \n",
    "                            palette=colors, edgecolor='#494949', lw=0.8, s=20, alpha=0.7)\n",
    "            for c, g_lab in enumerate(grp_conditions.keys()):\n",
    "                sns.regplot(ax=ax, x='Age_z', y=f'{dv}_pred', data=df_t[df_t['iv_group']==g_lab], color=colors[c], scatter=False)\n",
    "            ax.legend(title=dict_labels[iv], ncols=3, loc='upper center', frameon=False, bbox_to_anchor=(0.5, 1.2), \n",
    "                      handletextpad=0.1, columnspacing=2)\n",
    "            ax.set_ylabel(dict_labels[f'{dv}_pred'])\n",
    "            ax.set_xlabel(\"Age (z-scored)\")  \n",
    "            ax.set_ylim([-1.65, 1.65])\n",
    "\n",
    "            # Slope Analysis\n",
    "            # 1. Age Slopes in IV Groups\n",
    "            print(\"\\n=== Age Effects Across IV Groups ===\")\n",
    "            for iv_group, iv_level in grp_conditions.items():\n",
    "                group_size = df_t['iv_group'].value_counts()[iv_group]\n",
    "                slope, se, tval, pval, ci = simple_slope_analysis(\n",
    "                    model=s3_model,\n",
    "                    level=iv_level,\n",
    "                    var='Age_z',\n",
    "                    interaction=f'Age_{iv}'\n",
    "                )\n",
    "                print(f\"\\n{iv_group} IV Group (n={group_size}):\")\n",
    "                print(f\"Age Slope: {slope:.3f} [95% CI: {ci[0]:.3f}, {ci[1]:.3f}], t = {tval:.2f}, p = {pval:.3f}\")\n",
    "\n",
    "            # # 2. IV Slopes in Age Groups\n",
    "            # print(\"\\n=== IV Effects Across Age Groups ===\")\n",
    "            # age_group_levels = {\n",
    "            #     'Young (≤-1SD)': -1,\n",
    "            #     'Middle Aged': 0,\n",
    "            #     'Old (≥1SD)': 1\n",
    "            # }\n",
    "            # for age_group, age_level in age_group_levels.items():\n",
    "            #     group_size = df_t['age_group'].value_counts()[age_group]\n",
    "            #     slope, se, tval, pval, ci = simple_slope_analysis(\n",
    "            #         model=s3_model,\n",
    "            #         level=age_level,\n",
    "            #         var=f'{iv}_z',\n",
    "            #         interaction=f'Age_{iv}'\n",
    "            #     )\n",
    "            #     print(f\"\\n{age_group} Group (n={group_size}):\")\n",
    "            #     print(f\"{iv} Slope: {slope:.3f} [95% CI: {ci[0]:.3f}, {ci[1]:.3f}], t = {tval:.2f}, p = {pval:.3f}\")\n",
    "\n",
    "            i += 1\n",
    "\n",
    "plt.tight_layout(pad=-0.3)\n",
    "# plt.savefig('results/plots/simpleslopesplot.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
